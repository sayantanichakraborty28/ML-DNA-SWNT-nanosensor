{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMkY9154KhetzaxRkT391NP"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rDpvhNcQ-EaR","executionInfo":{"status":"ok","timestamp":1713832356455,"user_tz":360,"elapsed":64289,"user":{"displayName":"sayantani chakraborty","userId":"16261040588437306402"}},"outputId":"85ab2067-52db-45f8-db29-5f690368ee5c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting rdkit-pypi\n","  Downloading rdkit_pypi-2022.9.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (29.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m29.4/29.4 MB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rdkit-pypi) (1.25.2)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from rdkit-pypi) (9.4.0)\n","Installing collected packages: rdkit-pypi\n","Successfully installed rdkit-pypi-2022.9.5\n","Requirement already satisfied: openpyxl in /usr/local/lib/python3.10/dist-packages (3.1.2)\n","Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.10/dist-packages (from openpyxl) (1.1.0)\n","Requirement already satisfied: rdkit-pypi in /usr/local/lib/python3.10/dist-packages (2022.9.5)\n","Collecting avalon_framework\n","  Downloading avalon_framework-1.8.2.tar.gz (3.1 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rdkit-pypi) (1.25.2)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from rdkit-pypi) (9.4.0)\n","Building wheels for collected packages: avalon_framework\n","  Building wheel for avalon_framework (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for avalon_framework: filename=avalon_framework-1.8.2-py3-none-any.whl size=3864 sha256=c1b72d5b58b8cb38e9c756045e51aa7356fe55e0d4adc945185b9026edb9f65b\n","  Stored in directory: /root/.cache/pip/wheels/78/3f/5c/a65bfa8ce94f62739865cf30e5687272ee719961b4311d05e3\n","Successfully built avalon_framework\n","Installing collected packages: avalon_framework\n","Successfully installed avalon_framework-1.8.2\n"]}],"source":["!pip install rdkit-pypi\n","!pip install openpyxl\n","!pip install rdkit-pypi avalon_framework"]},{"cell_type":"code","source":["from rdkit import Chem\n","from rdkit.Chem import AllChem\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.svm import SVC\n","#from imblearn.over_sampling import RandomOverSampler\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, recall_score\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from google.colab import files\n","import numpy as np\n","import pandas as pd\n","from sklearn.metrics import roc_curve, auc\n","from sklearn.model_selection import learning_curve"],"metadata":{"id":"a5zc7ATC-FSj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Morgan"],"metadata":{"id":"yYAiSVVTJRUa"}},{"cell_type":"code","source":["# Load the Excel file containing SMILES, CLASS, HOMO, and LUMO data\n","df = pd.read_excel('HOMO-LUMO-energies.xlsx')  # Replace 'your_excel_file.xlsx' with the actual file name\n","\n","# Define column names for better clarity\n","column_names = [\"Cmpd Lab\", \"Smiles\", \"dFF\", \"HOMO (eV)\", \"LUMO (eV)\"]\n","\n","# Rename the DataFrame columns\n","df.columns = column_names\n","\n","# Extract columns using descriptive variable names\n","smiles_column = df['Smiles']\n","ff_column = df['dFF']\n","homo_column = df['HOMO (eV)']\n","lumo_column = df['LUMO (eV)']\n","\n","# Convert SMILES column to a list\n","smiles_list = smiles_column.to_list()\n","\n","# Convert F/F columns to numeric arrays\n","ff_values = ff_column.to_numpy().astype(float)\n","\n","# Convert HOMO and LUMO columns to numeric arrays\n","homo_values = homo_column.to_numpy().astype(float)\n","lumo_values = lumo_column.to_numpy().astype(float)\n","\n","# Create RDKit Mol objects from SMILES\n","mols = [Chem.MolFromSmiles(smiles) for smiles in smiles_list]\n","\n","# Generate fingerprints using RDKit's Morgan fingerprint\n","fingerprints = [AllChem.GetMorganFingerprintAsBitVect(mol, 2) for mol in mols]\n","\n","# Create 'labels' array based on positive and negative numbers\n","df[\"Class\"] = (df[\"dFF\"] > 0.3).astype(int)\n","\n","# Set a fixed random seed for reproducibility\n","seed_value = 45\n","np.random.seed(seed_value)\n","\n","# Convert RDKit fingerprints to a list of lists\n","fingerprints_list = [list(fp.ToBitString()) for fp in fingerprints]\n","\n","# Combine fingerprints, HOMO, and LUMO into features\n","features = np.column_stack((np.array(fingerprints_list), homo_values, lumo_values))\n","\n","# Create a new DataFrame with molecular features and class labels\n","new_df = pd.DataFrame(data={\"Class\": df[\"Class\"], \"Features\": list(features)})\n","\n","# Split the data into features (X) and labels (y)\n","X = pd.DataFrame(new_df[\"Features\"].to_list(), columns=[f\"Feature_{i}\" for i in range(2048 + 2)])  # Assuming 2048 fingerprint features\n","y = new_df[\"Class\"]\n","\n","print(\"Shape of X:\", X.shape)\n","\n","\n","# Use fingerprints directly for features\n","#features = np.array(fingerprints_list)\n","\n","# Initialize lists to store evaluation metrics and confusion matrices\n","confusion_matrix_list = []\n","metrics_list = []\n","\n","num_models = 200\n","\n","# Initialize variables to track the 5 best models within the specified f1 score range\n","top_models_indices = []\n","top_models_f1_scores = []\n","top_models_accuracies = []\n","top_models = []  # Store the models\n","\n","f1_range_lower = 0.75\n","f1_range_upper = 0.9\n","\n","# Run the model 200 times with different random states\n","for i in range(num_models):\n","    # Shuffle the data using a random number generator\n","    permutation = np.random.permutation(len(X))\n","    shuffled_X = X.iloc[permutation]\n","    shuffled_labels = new_df[\"Class\"].iloc[permutation]\n","\n","    # Split the shuffled features and labels into training and testing datasets\n","    x_train, x_test, y_train, y_test = train_test_split(shuffled_X, shuffled_labels, test_size=0.20, random_state=i)\n","\n","\n","    #print(\"Shape of X_train:\", x_train.shape)\n","\n","\n","    # Initialize and train the SVC model\n","    model = SVC(probability=True)\n","    model.fit(x_train, y_train)\n","\n","    # Make predictions on the test set\n","    y_pred = model.predict(x_test)\n","    y_prob = model.predict_proba(x_test)[:, 1]\n","\n","    # Calculate metrics\n","    accuracy = accuracy_score(y_test, y_pred)\n","    f1 = f1_score(y_test, y_pred)\n","    cm = confusion_matrix(y_test, y_pred)\n","    recall = recall_score(y_test, y_pred)\n","\n","    # Append metrics to the list\n","    metrics_list.append({\"Model\": i + 1, \"Accuracy\": accuracy, \"F1 Score\": f1, \"Recall\": recall})\n","    confusion_matrix_list.append(cm)\n","\n","    # Update top models list if f1 score is within the specified range\n","    if f1_range_lower <= f1 <= f1_range_upper:\n","        top_models_indices.append(i)\n","        top_models_f1_scores.append(f1)\n","        top_models_accuracies.append(accuracy)\n","        top_models.append(model)  # Store the model\n","\n","# Sort top models based on f1 score in descending order\n","sorted_top_models_indices = [idx for idx, _ in sorted(enumerate(top_models_f1_scores), key=lambda x: x[1], reverse=True)]\n","top_models_indices = [top_models_indices[idx] for idx in sorted_top_models_indices[:5]]\n","\n","# Save the indices, f1 scores, and accuracies to a file for the top 5 models\n","top_models_info = pd.DataFrame({\"Model Index\": top_models_indices[:5], \"F1 Score\": top_models_f1_scores[:5], \"Accuracy\": top_models_accuracies[:5]})\n","top_models_info.to_csv(\"class-topmodels_info-seed45-Morgan-t3-energy.csv\", index=False)\n","\n","# For predicting new molecules\n","# Load new molecule features\n","df_new = pd.read_csv('INPUT-NEW-MOLS-correct-HOMOLUMO.csv')\n","new_smiles_list = df_new[\"Smiles\"]\n","new_molecule_names = df_new[\"Cmpd Label\"]\n","new_mols = [Chem.MolFromSmiles(smiles) for smiles in new_smiles_list]\n","new_Morgan_fingerprints = [AllChem.GetMorganFingerprintAsBitVect(mol, 2) for mol in new_mols]\n","\n","# Extract HOMO and LUMO columns for new molecules\n","new_homo_values = df_new['HOMO (eV)'].astype(float)\n","new_lumo_values = df_new['LUMO (eV)'].astype(float)\n","\n","# Combine fingerprints, HOMO, and LUMO for new molecules\n","new_features = np.column_stack((np.array(new_Morgan_fingerprints)[:, :2048], new_homo_values, new_lumo_values))\n","\n","\n","# Initialize predictions_df DataFrame with molecule names\n","predictions_df = pd.DataFrame({\"Molecule Names\": new_molecule_names})\n","\n","# Iterate over the top 5 models\n","for idx, model in enumerate(top_models[:5]):\n","    # Use the model to predict classes for new molecules\n","    predictions = model.predict(new_features)\n","\n","    # Save predictions to the DataFrame\n","    predictions_df[f'Model_{idx + 1}_Predictions'] = predictions\n","\n","# Save predictions to a CSV file\n","predictions_df.to_csv(\"class-predictions-seed45-Morgan-t3-energy-AllModels.csv\", index=False)\n","\n","\n","\n","\n","\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZiT-2_N4DNS5","executionInfo":{"status":"ok","timestamp":1713824236630,"user_tz":360,"elapsed":62729,"user":{"displayName":"sayantani chakraborty","userId":"16261040588437306402"}},"outputId":"2e321d29-57d8-4680-a202-dc70751c3324"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Shape of X: (63, 2050)\n"]}]},{"cell_type":"markdown","source":["# MACCS"],"metadata":{"id":"UG1BkSnabh5k"}},{"cell_type":"code","source":["from rdkit.Chem import MACCSkeys\n","\n","# Load the Excel file containing SMILES, CLASS, HOMO, and LUMO data\n","df = pd.read_excel('HOMO-LUMO-energies.xlsx')  # Replace 'your_excel_file.xlsx' with the actual file name\n","\n","# Define column names for better clarity\n","column_names = [\"Cmpd Lab\", \"Smiles\", \"dFF\", \"HOMO (eV)\", \"LUMO (eV)\"]\n","\n","# Rename the DataFrame columns\n","df.columns = column_names\n","\n","# Extract columns using descriptive variable names\n","smiles_column = df['Smiles']\n","ff_column = df['dFF']\n","homo_column = df['HOMO (eV)']\n","lumo_column = df['LUMO (eV)']\n","\n","# Convert SMILES column to a list\n","smiles_list = smiles_column.to_list()\n","\n","# Convert F/F columns to numeric arrays\n","ff_values = ff_column.to_numpy().astype(float)\n","\n","# Convert HOMO and LUMO columns to numeric arrays\n","homo_values = homo_column.to_numpy().astype(float)\n","lumo_values = lumo_column.to_numpy().astype(float)\n","\n","# Create RDKit Mol objects from SMILES\n","mols = [Chem.MolFromSmiles(smiles) for smiles in smiles_list]\n","\n","# Generate fingerprints using RDKit's MACCS fingerprint\n","fingerprints = [MACCSkeys.GenMACCSKeys(mol) for mol in mols]\n","\n","# Create 'labels' array based on positive and negative numbers\n","df[\"Class\"] = (df[\"dFF\"] > 0.3).astype(int)\n","\n","# Set a fixed random seed for reproducibility\n","seed_value = 45\n","np.random.seed(seed_value)\n","\n","# Convert RDKit fingerprints to a list of lists\n","fingerprints_list = [list(fp.ToBitString()) for fp in fingerprints]\n","\n","# Combine fingerprints, HOMO, and LUMO into features\n","features = np.column_stack((np.array(fingerprints_list), homo_values, lumo_values))\n","\n","# Create a new DataFrame with molecular features and class labels\n","new_df = pd.DataFrame(data={\"Class\": df[\"Class\"], \"Features\": list(features)})\n","\n","# Split the data into features (X) and labels (y)\n","X = pd.DataFrame(new_df[\"Features\"].to_list(), columns=[f\"Feature_{i}\" for i in range(167 + 2)])  # Assuming 167 MACCS fingerprint features\n","y = new_df[\"Class\"]\n","\n","print(\"Shape of X:\", X.shape)\n","\n","# Use fingerprints directly for features\n","#features = np.array(fingerprints_list)\n","\n","# Initialize lists to store evaluation metrics and confusion matrices\n","confusion_matrix_list = []\n","metrics_list = []\n","\n","num_models = 200\n","\n","# Initialize variables to track the 5 best models within the specified f1 score range\n","top_models_indices = []\n","top_models_f1_scores = []\n","top_models_accuracies = []\n","top_models = []  # Store the models\n","\n","f1_range_lower = 0.75\n","f1_range_upper = 0.9\n","\n","# Run the model 200 times with different random states\n","for i in range(num_models):\n","    # Shuffle the data using a random number generator\n","    permutation = np.random.permutation(len(X))\n","    shuffled_X = X.iloc[permutation]\n","    shuffled_labels = new_df[\"Class\"].iloc[permutation]\n","\n","    # Split the shuffled features and labels into training and testing datasets\n","    x_train, x_test, y_train, y_test = train_test_split(shuffled_X, shuffled_labels, test_size=0.20, random_state=i)\n","\n","\n","    #print(\"Shape of X_train:\", x_train.shape)\n","\n","\n","    # Initialize and train the SVC model\n","    model = SVC(probability=True)\n","    model.fit(x_train, y_train)\n","\n","    # Make predictions on the test set\n","    y_pred = model.predict(x_test)\n","    y_prob = model.predict_proba(x_test)[:, 1]\n","\n","    # Calculate metrics\n","    accuracy = accuracy_score(y_test, y_pred)\n","    f1 = f1_score(y_test, y_pred)\n","    cm = confusion_matrix(y_test, y_pred)\n","    recall = recall_score(y_test, y_pred)\n","\n","    # Append metrics to the list\n","    metrics_list.append({\"Model\": i + 1, \"Accuracy\": accuracy, \"F1 Score\": f1, \"Recall\": recall})\n","    confusion_matrix_list.append(cm)\n","\n","    # Update top models list if f1 score is within the specified range\n","    if f1_range_lower <= f1 <= f1_range_upper:\n","        top_models_indices.append(i)\n","        top_models_f1_scores.append(f1)\n","        top_models_accuracies.append(accuracy)\n","        top_models.append(model)  # Store the model\n","\n","# Sort top models based on f1 score in descending order\n","sorted_top_models_indices = [idx for idx, _ in sorted(enumerate(top_models_f1_scores), key=lambda x: x[1], reverse=True)]\n","top_models_indices = [top_models_indices[idx] for idx in sorted_top_models_indices[:5]]\n","\n","# Save the indices, f1 scores, and accuracies to a file for the top 5 models\n","top_models_info = pd.DataFrame({\"Model Index\": top_models_indices[:5], \"F1 Score\": top_models_f1_scores[:5], \"Accuracy\": top_models_accuracies[:5]})\n","top_models_info.to_csv(\"class-topmodels_info-seed45-Maccs-t3-energy.csv\", index=False)\n","\n","# For predicting new molecules\n","# Load new molecule features\n","df_new = pd.read_csv('INPUT-NEW-MOLS-correct-HOMOLUMO.csv')\n","new_smiles_list = df_new[\"Smiles\"]\n","new_molecule_names = df_new[\"Cmpd Label\"]\n","new_mols = [Chem.MolFromSmiles(smiles) for smiles in new_smiles_list]\n","new_maccs_fingerprints = [MACCSkeys.GenMACCSKeys(mol) for mol in new_mols]\n","\n","# Extract HOMO and LUMO columns for new molecules\n","new_homo_values = df_new['HOMO (eV)'].astype(float)\n","new_lumo_values = df_new['LUMO (eV)'].astype(float)\n","\n","# Combine fingerprints, HOMO, and LUMO for new molecules\n","new_features = np.column_stack((np.array(new_maccs_fingerprints)[:, :167], new_homo_values, new_lumo_values))\n","\n","\n","# Initialize predictions_df DataFrame with molecule names\n","predictions_df = pd.DataFrame({\"Molecule Names\": new_molecule_names})\n","\n","# Iterate over the top 5 models\n","for idx, model in enumerate(top_models[:5]):\n","    # Use the model to predict classes for new molecules\n","    predictions = model.predict(new_features)\n","\n","    # Save predictions to the DataFrame\n","    predictions_df[f'Model_{idx + 1}_Predictions'] = predictions\n","\n","# Save predictions to a CSV file\n","predictions_df.to_csv(\"class-predictions-seed45-MACCS-t3-energy-AllModels.csv\", index=False)\n","\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Y9bMxjfpauE-","executionInfo":{"status":"ok","timestamp":1713824468728,"user_tz":360,"elapsed":10500,"user":{"displayName":"sayantani chakraborty","userId":"16261040588437306402"}},"outputId":"9895accb-d4a8-477c-d2e1-e1caa67199a3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Shape of X: (63, 169)\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but SVC was fitted with feature names\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but SVC was fitted with feature names\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but SVC was fitted with feature names\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but SVC was fitted with feature names\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but SVC was fitted with feature names\n","  warnings.warn(\n"]}]},{"cell_type":"markdown","source":["# Daylight"],"metadata":{"id":"4k6qaJOBgGNx"}},{"cell_type":"markdown","source":[],"metadata":{"id":"PskB1Vhwc3Yu"}},{"cell_type":"code","source":[],"metadata":{"id":"bU0PS_Aqcc0r"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from rdkit import Chem\n","from rdkit.Chem import DataStructs\n","\n","# Load the Excel file containing SMILES, CLASS, HOMO, and LUMO data\n","df = pd.read_excel('HOMO-LUMO-energies.xlsx')  # Replace 'your_excel_file.xlsx' with the actual file name\n","\n","# Define column names for better clarity\n","column_names = [\"Cmpd Lab\", \"Smiles\", \"dFF\", \"HOMO (eV)\", \"LUMO (eV)\"]\n","\n","# Rename the DataFrame columns\n","df.columns = column_names\n","\n","# Extract columns using descriptive variable names\n","smiles_column = df['Smiles']\n","ff_column = df['dFF']\n","homo_column = df['HOMO (eV)']\n","lumo_column = df['LUMO (eV)']\n","\n","# Convert SMILES column to a list\n","smiles_list = smiles_column.to_list()\n","\n","# Convert F/F columns to numeric arrays\n","ff_values = ff_column.to_numpy().astype(float)\n","\n","# Convert HOMO and LUMO columns to numeric arrays\n","homo_values = homo_column.to_numpy().astype(float)\n","lumo_values = lumo_column.to_numpy().astype(float)\n","\n","# Create RDKit Mol objects from SMILES\n","mols = [Chem.MolFromSmiles(smiles) for smiles in smiles_list]\n","\n","# Create RDKit Mol objects from SMILES\n","Daylight_fingerprints = [Chem.RDKFingerprint(mol) for mol in mols]\n","\n","# Create 'labels' array based on positive and negative numbers\n","df[\"Class\"] = (df[\"dFF\"] > 0.3).astype(int)\n","\n","# Set a fixed random seed for reproducibility\n","seed_value = 45\n","np.random.seed(seed_value)\n","\n","# Convert RDKit fingerprints to a list of lists\n","fingerprints_list = [list(fp.ToBitString()) for fp in Daylight_fingerprints]\n","\n","# Combine fingerprints, HOMO, and LUMO into features\n","features = np.column_stack((np.array(fingerprints_list), homo_values, lumo_values))\n","\n","# Create a new DataFrame with molecular features and class labels\n","new_df = pd.DataFrame(data={\"Class\": df[\"Class\"], \"Features\": list(features)})\n","\n","# Split the data into features (X) and labels (y)\n","X = pd.DataFrame(new_df[\"Features\"].to_list(), columns=[f\"Feature_{i}\" for i in range(2048 + 2)])\n","y = new_df[\"Class\"]\n","\n","print(\"Shape of X:\", X.shape)\n","\n","# Use fingerprints directly for features\n","#features = np.array(fingerprints_list)\n","\n","# Initialize lists to store evaluation metrics and confusion matrices\n","confusion_matrix_list = []\n","metrics_list = []\n","\n","num_models = 200\n","\n","# Initialize variables to track the 5 best models within the specified f1 score range\n","top_models_indices = []\n","top_models_f1_scores = []\n","top_models_accuracies = []\n","top_models = []  # Store the models\n","\n","f1_range_lower = 0.75\n","f1_range_upper = 0.9\n","\n","# Run the model 200 times with different random states\n","for i in range(num_models):\n","    # Shuffle the data using a random number generator\n","    permutation = np.random.permutation(len(X))\n","    shuffled_X = X.iloc[permutation]\n","    shuffled_labels = new_df[\"Class\"].iloc[permutation]\n","\n","    # Split the shuffled features and labels into training and testing datasets\n","    x_train, x_test, y_train, y_test = train_test_split(shuffled_X, shuffled_labels, test_size=0.20, random_state=i)\n","\n","\n","    #print(\"Shape of X_train:\", x_train.shape)\n","\n","\n","    # Initialize and train the SVC model\n","    model = SVC(probability=True)\n","    model.fit(x_train, y_train)\n","\n","    # Make predictions on the test set\n","    y_pred = model.predict(x_test)\n","    y_prob = model.predict_proba(x_test)[:, 1]\n","\n","    # Calculate metrics\n","    accuracy = accuracy_score(y_test, y_pred)\n","    f1 = f1_score(y_test, y_pred)\n","    cm = confusion_matrix(y_test, y_pred)\n","    recall = recall_score(y_test, y_pred)\n","\n","    # Append metrics to the list\n","    metrics_list.append({\"Model\": i + 1, \"Accuracy\": accuracy, \"F1 Score\": f1, \"Recall\": recall})\n","    confusion_matrix_list.append(cm)\n","\n","    # Update top models list if f1 score is within the specified range\n","    if f1_range_lower <= f1 <= f1_range_upper:\n","        top_models_indices.append(i)\n","        top_models_f1_scores.append(f1)\n","        top_models_accuracies.append(accuracy)\n","        top_models.append(model)  # Store the model\n","\n","# Sort top models based on f1 score in descending order\n","sorted_top_models_indices = [idx for idx, _ in sorted(enumerate(top_models_f1_scores), key=lambda x: x[1], reverse=True)]\n","top_models_indices = [top_models_indices[idx] for idx in sorted_top_models_indices[:5]]\n","\n","# Save the indices, f1 scores, and accuracies to a file for the top 5 models\n","top_models_info = pd.DataFrame({\"Model Index\": top_models_indices[:5], \"F1 Score\": top_models_f1_scores[:5], \"Accuracy\": top_models_accuracies[:5]})\n","top_models_info.to_csv(\"class-topmodels_info-seed45-Daylight-t3-energy.csv\", index=False)\n","\n","# For predicting new molecules\n","# Load new molecule features\n","df_new = pd.read_csv('INPUT-NEW-MOLS-correct-HOMOLUMO.csv')\n","new_smiles_list = df_new[\"Smiles\"]\n","new_molecule_names = df_new[\"Cmpd Label\"]\n","new_mols = [Chem.MolFromSmiles(smiles) for smiles in new_smiles_list]\n","new_Daylight_fingerprints = [Chem.RDKFingerprint(mol) for mol in new_mols]\n","\n","# Extract HOMO and LUMO columns for new molecules\n","new_homo_values = df_new['HOMO (eV)'].astype(float)\n","new_lumo_values = df_new['LUMO (eV)'].astype(float)\n","\n","# Combine fingerprints, HOMO, and LUMO for new molecules\n","new_features = np.column_stack((np.array(new_Daylight_fingerprints)[:, :2048], new_homo_values, new_lumo_values))\n","\n","\n","# Initialize predictions_df DataFrame\n","predictions_df = pd.DataFrame({\"Molecule Names\": new_molecule_names, \"Molecule SMILES\": new_smiles_list})\n","\n","# Iterate over the top 5 models\n","for idx, model in enumerate(top_models[:5]):\n","    # Assuming X_train is a DataFrame with named columns\n","    feature_names = X.columns.tolist()\n","    new_features_df = pd.DataFrame(new_features, columns=feature_names)\n","\n","    # Use the model to predict classes for new molecules\n","    predictions = model.predict(new_features_df)\n","\n","    # Save predictions to the DataFrame\n","    predictions_df[f'Model_{idx + 1}_Predictions'] = predictions\n","\n","    # Save predictions to a CSV file\n","    model_predictions_filename = f\"class-predictions-seed45-daylight-t3-energy-Model{top_models_indices[idx] + 1}.csv\"\n","    predictions_df[['Molecule Names', f'Model_{idx + 1}_Predictions']].to_csv(model_predictions_filename, index=False)\n","\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":373},"executionInfo":{"status":"error","timestamp":1713825748880,"user_tz":360,"elapsed":40972,"user":{"displayName":"sayantani chakraborty","userId":"16261040588437306402"}},"outputId":"70abeb0e-6b6d-431d-fecf-5c78feba0fc7","id":"iQeV9tWZc47V"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Shape of X: (63, 2050)\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-9-a4b3151bad95>\u001b[0m in \u001b[0;36m<cell line: 76>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;31m# Initialize and train the SVC model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSVC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobability\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;31m# Make predictions on the test set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0mseed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"i\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m         \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    253\u001b[0m         \u001b[0;31m# see comment on the other call to np.iinfo in this file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py\u001b[0m in \u001b[0;36m_dense_fit\u001b[0;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001b[0m\n\u001b[1;32m    329\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_status_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_iter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m         \u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibsvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"markdown","source":["# Atompairs"],"metadata":{"id":"WLxMmbszgKuE"}},{"cell_type":"code","source":[],"metadata":{"id":"OHKIJCPIfKhp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from rdkit.Chem import rdMolDescriptors\n","\n","# Load the Excel file containing SMILES, CLASS, HOMO, and LUMO data\n","df = pd.read_excel('HOMO-LUMO-energies.xlsx')  # Replace 'your_excel_file.xlsx' with the actual file name\n","\n","# Define column names for better clarity\n","column_names = [\"Cmpd Lab\", \"Smiles\", \"dFF\", \"HOMO (eV)\", \"LUMO (eV)\"]\n","\n","# Rename the DataFrame columns\n","df.columns = column_names\n","\n","# Extract columns using descriptive variable names\n","smiles_column = df['Smiles']\n","ff_column = df['dFF']\n","homo_column = df['HOMO (eV)']\n","lumo_column = df['LUMO (eV)']\n","\n","# Convert SMILES column to a list\n","smiles_list = smiles_column.to_list()\n","\n","# Convert F/F columns to numeric arrays\n","ff_values = ff_column.to_numpy().astype(float)\n","\n","# Convert HOMO and LUMO columns to numeric arrays\n","homo_values = homo_column.to_numpy().astype(float)\n","lumo_values = lumo_column.to_numpy().astype(float)\n","\n","# Create RDKit Mol objects from SMILES\n","mols = [Chem.MolFromSmiles(smiles) for smiles in smiles_list]\n","atom_pairs_fingerprints = [rdMolDescriptors.GetHashedAtomPairFingerprintAsBitVect(mol) for mol in mols]\n","\n","# Create 'labels' array based on positive and negative numbers\n","df[\"Class\"] = (df[\"dFF\"] > 0.3).astype(int)\n","\n","# Set a fixed random seed for reproducibility\n","seed_value = 45\n","np.random.seed(seed_value)\n","\n","# Convert RDKit fingerprints to a list of lists\n","fingerprints_list = [list(fp.ToBitString()) for fp in atom_pairs_fingerprints]\n","\n","# Combine fingerprints, HOMO, and LUMO into features\n","features = np.column_stack((np.array(fingerprints_list), homo_values, lumo_values))\n","\n","# Create a new DataFrame with molecular features and class labels\n","new_df = pd.DataFrame(data={\"Class\": df[\"Class\"], \"Features\": list(features)})\n","\n","# Split the data into features (X) and labels (y)\n","X = pd.DataFrame(new_df[\"Features\"].to_list(), columns=[f\"Feature_{i}\" for i in range(2048 + 2)])\n","y = new_df[\"Class\"]\n","\n","print(\"Shape of X:\", X.shape)\n","\n","# Use fingerprints directly for features\n","#features = np.array(fingerprints_list)\n","\n","# Initialize lists to store evaluation metrics and confusion matrices\n","confusion_matrix_list = []\n","metrics_list = []\n","\n","num_models = 200\n","\n","# Initialize variables to track the 5 best models within the specified f1 score range\n","top_models_indices = []\n","top_models_f1_scores = []\n","top_models_accuracies = []\n","top_models = []  # Store the models\n","\n","f1_range_lower = 0.75\n","f1_range_upper = 0.9\n","\n","# Run the model 200 times with different random states\n","for i in range(num_models):\n","    # Shuffle the data using a random number generator\n","    permutation = np.random.permutation(len(X))\n","    shuffled_X = X.iloc[permutation]\n","    shuffled_labels = new_df[\"Class\"].iloc[permutation]\n","\n","    # Split the shuffled features and labels into training and testing datasets\n","    x_train, x_test, y_train, y_test = train_test_split(shuffled_X, shuffled_labels, test_size=0.20, random_state=i)\n","\n","\n","    #print(\"Shape of X_train:\", x_train.shape)\n","\n","\n","    # Initialize and train the SVC model\n","    model = SVC(probability=True)\n","    model.fit(x_train, y_train)\n","\n","    # Make predictions on the test set\n","    y_pred = model.predict(x_test)\n","    y_prob = model.predict_proba(x_test)[:, 1]\n","\n","    # Calculate metrics\n","    accuracy = accuracy_score(y_test, y_pred)\n","    f1 = f1_score(y_test, y_pred)\n","    cm = confusion_matrix(y_test, y_pred)\n","    recall = recall_score(y_test, y_pred)\n","\n","    # Append metrics to the list\n","    metrics_list.append({\"Model\": i + 1, \"Accuracy\": accuracy, \"F1 Score\": f1, \"Recall\": recall})\n","    confusion_matrix_list.append(cm)\n","\n","    # Update top models list if f1 score is within the specified range\n","    if f1_range_lower <= f1 <= f1_range_upper:\n","        top_models_indices.append(i)\n","        top_models_f1_scores.append(f1)\n","        top_models_accuracies.append(accuracy)\n","        top_models.append(model)  # Store the model\n","\n","# Sort top models based on f1 score in descending order\n","sorted_top_models_indices = [idx for idx, _ in sorted(enumerate(top_models_f1_scores), key=lambda x: x[1], reverse=True)]\n","top_models_indices = [top_models_indices[idx] for idx in sorted_top_models_indices[:5]]\n","\n","# Save the indices, f1 scores, and accuracies to a file for the top 5 models\n","top_models_info = pd.DataFrame({\"Model Index\": top_models_indices[:5], \"F1 Score\": top_models_f1_scores[:5], \"Accuracy\": top_models_accuracies[:5]})\n","top_models_info.to_csv(\"class-topmodels_info-seed45-atompairs-t3-energy.csv\", index=False)\n","\n","# For predicting new molecules\n","# Load new molecule features\n","df_new = pd.read_csv('INPUT-NEW-MOLS-correct-HOMOLUMO.csv')\n","new_smiles_list = df_new[\"Smiles\"]\n","new_molecule_names = df_new[\"Cmpd Label\"]\n","new_mols = [Chem.MolFromSmiles(smiles) for smiles in new_smiles_list]\n","new_atom_pairs_fingerprints = [rdMolDescriptors.GetHashedAtomPairFingerprintAsBitVect(mol) for mol in new_mols]\n","\n","# Extract HOMO and LUMO columns for new molecules\n","new_homo_values = df_new['HOMO (eV)'].astype(float)\n","new_lumo_values = df_new['LUMO (eV)'].astype(float)\n","\n","# Combine fingerprints, HOMO, and LUMO for new molecules\n","new_features = np.column_stack((np.array(new_atom_pairs_fingerprints)[:, :2048], new_homo_values, new_lumo_values))\n","\n","\n","# Initialize predictions_df DataFrame\n","predictions_df = pd.DataFrame({\"Molecule Names\": new_molecule_names, \"Molecule SMILES\": new_smiles_list})\n","\n","# Iterate over the top 5 models\n","for idx, model in enumerate(top_models[:5]):\n","    # Assuming X_train is a DataFrame with named columns\n","    feature_names = X.columns.tolist()\n","    new_features_df = pd.DataFrame(new_features, columns=feature_names)\n","\n","    # Use the model to predict classes for new molecules\n","    predictions = model.predict(new_features_df)\n","\n","    # Save predictions to the DataFrame\n","    predictions_df[f'Model_{idx + 1}_Predictions'] = predictions\n","\n","    # Save predictions to a CSV file\n","    model_predictions_filename = f\"class-predictions-seed45-atompairs-t3-energy-Model{top_models_indices[idx] + 1}.csv\"\n","    predictions_df[['Molecule Names', f'Model_{idx + 1}_Predictions']].to_csv(model_predictions_filename, index=False)\n","\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1713832441980,"user_tz":360,"elapsed":82899,"user":{"displayName":"sayantani chakraborty","userId":"16261040588437306402"}},"outputId":"859669b9-b89d-42ee-d74f-8bebc5021f64","id":"K3uJ_FzefLA2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Shape of X: (63, 2050)\n"]}]},{"cell_type":"markdown","source":["# Avalon"],"metadata":{"id":"rynnvIfXkqDD"}},{"cell_type":"code","source":[],"metadata":{"id":"curZ4hJpknwU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from rdkit import Chem\n","from rdkit.Avalon import pyAvalonTools\n","\n","# Load the Excel file containing SMILES, CLASS, HOMO, and LUMO data\n","df = pd.read_excel('HOMO-LUMO-energies.xlsx')  # Replace 'your_excel_file.xlsx' with the actual file name\n","\n","# Define column names for better clarity\n","column_names = [\"Cmpd Lab\", \"Smiles\", \"dFF\", \"HOMO (eV)\", \"LUMO (eV)\"]\n","\n","# Rename the DataFrame columns\n","df.columns = column_names\n","\n","# Extract columns using descriptive variable names\n","smiles_column = df['Smiles']\n","ff_column = df['dFF']\n","homo_column = df['HOMO (eV)']\n","lumo_column = df['LUMO (eV)']\n","\n","# Convert SMILES column to a list\n","smiles_list = smiles_column.to_list()\n","\n","# Convert F/F columns to numeric arrays\n","ff_values = ff_column.to_numpy().astype(float)\n","\n","# Convert HOMO and LUMO columns to numeric arrays\n","homo_values = homo_column.to_numpy().astype(float)\n","lumo_values = lumo_column.to_numpy().astype(float)\n","\n","# Create RDKit Mol objects from SMILES\n","mols = [Chem.MolFromSmiles(smiles) for smiles in smiles_list]\n","Avalon_fingerprints = [pyAvalonTools.GetAvalonFP(mol) for mol in mols]\n","\n","# Create 'labels' array based on positive and negative numbers\n","df[\"Class\"] = (df[\"dFF\"] > 0.3).astype(int)\n","\n","# Set a fixed random seed for reproducibility\n","seed_value = 45\n","np.random.seed(seed_value)\n","\n","# Convert RDKit fingerprints to a list of lists\n","fingerprints_list = [list(fp.ToBitString()) for fp in Avalon_fingerprints]\n","\n","# Combine fingerprints, HOMO, and LUMO into features\n","features = np.column_stack((np.array(fingerprints_list), homo_values, lumo_values))\n","\n","# Create a new DataFrame with molecular features and class labels\n","new_df = pd.DataFrame(data={\"Class\": df[\"Class\"], \"Features\": list(features)})\n","\n","# Split the data into features (X) and labels (y)\n","X = pd.DataFrame(new_df[\"Features\"].to_list(), columns=[f\"Feature_{i}\" for i in range(512 + 2)])\n","y = new_df[\"Class\"]\n","\n","print(\"Shape of X:\", X.shape)\n","\n","# Use fingerprints directly for features\n","#features = np.array(fingerprints_list)\n","\n","# Initialize lists to store evaluation metrics and confusion matrices\n","confusion_matrix_list = []\n","metrics_list = []\n","\n","num_models = 200\n","\n","# Initialize variables to track the 5 best models within the specified f1 score range\n","top_models_indices = []\n","top_models_f1_scores = []\n","top_models_accuracies = []\n","top_models = []  # Store the models\n","\n","f1_range_lower = 0.75\n","f1_range_upper = 0.9\n","\n","# Run the model 200 times with different random states\n","for i in range(num_models):\n","    # Shuffle the data using a random number generator\n","    permutation = np.random.permutation(len(X))\n","    shuffled_X = X.iloc[permutation]\n","    shuffled_labels = new_df[\"Class\"].iloc[permutation]\n","\n","    # Split the shuffled features and labels into training and testing datasets\n","    x_train, x_test, y_train, y_test = train_test_split(shuffled_X, shuffled_labels, test_size=0.20, random_state=i)\n","\n","\n","    #print(\"Shape of X_train:\", x_train.shape)\n","\n","\n","    # Initialize and train the SVC model\n","    model = SVC(probability=True)\n","    model.fit(x_train, y_train)\n","\n","    # Make predictions on the test set\n","    y_pred = model.predict(x_test)\n","    y_prob = model.predict_proba(x_test)[:, 1]\n","\n","    # Calculate metrics\n","    accuracy = accuracy_score(y_test, y_pred)\n","    f1 = f1_score(y_test, y_pred)\n","    cm = confusion_matrix(y_test, y_pred)\n","    recall = recall_score(y_test, y_pred)\n","\n","    # Append metrics to the list\n","    metrics_list.append({\"Model\": i + 1, \"Accuracy\": accuracy, \"F1 Score\": f1, \"Recall\": recall})\n","    confusion_matrix_list.append(cm)\n","\n","    # Update top models list if f1 score is within the specified range\n","    if f1_range_lower <= f1 <= f1_range_upper:\n","        top_models_indices.append(i)\n","        top_models_f1_scores.append(f1)\n","        top_models_accuracies.append(accuracy)\n","        top_models.append(model)  # Store the model\n","\n","# Sort top models based on f1 score in descending order\n","sorted_top_models_indices = [idx for idx, _ in sorted(enumerate(top_models_f1_scores), key=lambda x: x[1], reverse=True)]\n","top_models_indices = [top_models_indices[idx] for idx in sorted_top_models_indices[:5]]\n","\n","# Save the indices, f1 scores, and accuracies to a file for the top 5 models\n","top_models_info = pd.DataFrame({\"Model Index\": top_models_indices[:5], \"F1 Score\": top_models_f1_scores[:5], \"Accuracy\": top_models_accuracies[:5]})\n","top_models_info.to_csv(\"class-topmodels_info-seed45-avalon-t3-energy.csv\", index=False)\n","\n","# For predicting new molecules\n","# Load new molecule features\n","df_new = pd.read_csv('INPUT-NEW-MOLS-correct-HOMOLUMO.csv')\n","new_smiles_list = df_new[\"Smiles\"]\n","new_molecule_names = df_new[\"Cmpd Label\"]\n","new_mols = [Chem.MolFromSmiles(smiles) for smiles in new_smiles_list]\n","new_Avalon_fingerprints = [pyAvalonTools.GetAvalonFP(mol) for mol in new_mols]\n","\n","# Extract HOMO and LUMO columns for new molecules\n","new_homo_values = df_new['HOMO (eV)'].astype(float)\n","new_lumo_values = df_new['LUMO (eV)'].astype(float)\n","\n","# Combine fingerprints, HOMO, and LUMO for new molecules\n","new_features = np.column_stack((np.array(new_Avalon_fingerprints)[:, :2048], new_homo_values, new_lumo_values))\n","\n","\n","# Initialize predictions_df DataFrame\n","predictions_df = pd.DataFrame({\"Molecule Names\": new_molecule_names, \"Molecule SMILES\": new_smiles_list})\n","\n","# Iterate over the top 5 models\n","for idx, model in enumerate(top_models[:5]):\n","    # Assuming X_train is a DataFrame with named columns\n","    feature_names = X.columns.tolist()\n","    new_features_df = pd.DataFrame(new_features, columns=feature_names)\n","\n","    # Use the model to predict classes for new molecules\n","    predictions = model.predict(new_features_df)\n","\n","    # Save predictions to the DataFrame\n","    predictions_df[f'Model_{idx + 1}_Predictions'] = predictions\n","\n","    # Save predictions to a CSV file\n","    model_predictions_filename = f\"class-predictions-seed45-avalon-t3-energy-Model{top_models_indices[idx] + 1}.csv\"\n","    predictions_df[['Molecule Names', f'Model_{idx + 1}_Predictions']].to_csv(model_predictions_filename, index=False)\n","\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1701926252801,"user_tz":420,"elapsed":18489,"user":{"displayName":"sayantani chakraborty","userId":"16261040588437306402"}},"outputId":"114fb5a0-3628-43ba-e210-261402f7b78b","id":"7ShznmfpkoT-"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Shape of X: (63, 514)\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"mRyIfu6b6Q19"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from rdkit.Chem import rdMolDescriptors\n","\n","# Load the Excel file containing SMILES, CLASS, HOMO, and LUMO data\n","df = pd.read_excel('HOMO-LUMO-energies.xlsx')  # Replace 'your_excel_file.xlsx' with the actual file name\n","\n","# Define column names for better clarity\n","column_names = [\"Cmpd Lab\", \"Smiles\", \"dFF\", \"HOMO (eV)\", \"LUMO (eV)\"]\n","\n","# Rename the DataFrame columns\n","df.columns = column_names\n","\n","# Extract columns using descriptive variable names\n","smiles_column = df['Smiles']\n","ff_column = df['dFF']\n","homo_column = df['HOMO (eV)']\n","lumo_column = df['LUMO (eV)']\n","\n","# Convert SMILES column to a list\n","smiles_list = smiles_column.to_list()\n","\n","# Convert F/F columns to numeric arrays\n","ff_values = ff_column.to_numpy().astype(float)\n","\n","# Convert HOMO and LUMO columns to numeric arrays\n","homo_values = homo_column.to_numpy().astype(float)\n","lumo_values = lumo_column.to_numpy().astype(float)\n","\n","# Create RDKit Mol objects from SMILES\n","mols = [Chem.MolFromSmiles(smiles) for smiles in smiles_list]\n","torsion_fingerprints = [rdMolDescriptors.GetHashedTopologicalTorsionFingerprintAsBitVect(mol) for mol in mols]\n","\n","# Create 'labels' array based on positive and negative numbers\n","df[\"Class\"] = (df[\"dFF\"] > 0.3).astype(int)\n","\n","# Set a fixed random seed for reproducibility\n","seed_value = 45\n","np.random.seed(seed_value)\n","\n","# Convert RDKit fingerprints to a list of lists\n","fingerprints_list = [list(fp.ToBitString()) for fp in torsion_fingerprints]\n","\n","# Combine fingerprints, HOMO, and LUMO into features\n","features = np.column_stack((np.array(fingerprints_list), homo_values, lumo_values))\n","\n","# Create a new DataFrame with molecular features and class labels\n","new_df = pd.DataFrame(data={\"Class\": df[\"Class\"], \"Features\": list(features)})\n","\n","# Split the data into features (X) and labels (y)\n","X = pd.DataFrame(new_df[\"Features\"].to_list(), columns=[f\"Feature_{i}\" for i in range(2048 + 2)])\n","y = new_df[\"Class\"]\n","\n","print(\"Shape of X:\", X.shape)\n","\n","# Use fingerprints directly for features\n","#features = np.array(fingerprints_list)\n","\n","# Initialize lists to store evaluation metrics and confusion matrices\n","confusion_matrix_list = []\n","metrics_list = []\n","\n","num_models = 200\n","\n","# Initialize variables to track the 5 best models within the specified f1 score range\n","top_models_indices = []\n","top_models_f1_scores = []\n","top_models_accuracies = []\n","top_models = []  # Store the models\n","\n","f1_range_lower = 0.75\n","f1_range_upper = 0.9\n","\n","# Run the model 200 times with different random states\n","for i in range(num_models):\n","    # Shuffle the data using a random number generator\n","    permutation = np.random.permutation(len(X))\n","    shuffled_X = X.iloc[permutation]\n","    shuffled_labels = new_df[\"Class\"].iloc[permutation]\n","\n","    # Split the shuffled features and labels into training and testing datasets\n","    x_train, x_test, y_train, y_test = train_test_split(shuffled_X, shuffled_labels, test_size=0.20, random_state=i)\n","\n","\n","    #print(\"Shape of X_train:\", x_train.shape)\n","\n","\n","    # Initialize and train the SVC model\n","    model = SVC(probability=True)\n","    model.fit(x_train, y_train)\n","\n","    # Make predictions on the test set\n","    y_pred = model.predict(x_test)\n","    y_prob = model.predict_proba(x_test)[:, 1]\n","\n","    # Calculate metrics\n","    accuracy = accuracy_score(y_test, y_pred)\n","    f1 = f1_score(y_test, y_pred)\n","    cm = confusion_matrix(y_test, y_pred)\n","    recall = recall_score(y_test, y_pred)\n","\n","    # Append metrics to the list\n","    metrics_list.append({\"Model\": i + 1, \"Accuracy\": accuracy, \"F1 Score\": f1, \"Recall\": recall})\n","    confusion_matrix_list.append(cm)\n","\n","    # Update top models list if f1 score is within the specified range\n","    if f1_range_lower <= f1 <= f1_range_upper:\n","        top_models_indices.append(i)\n","        top_models_f1_scores.append(f1)\n","        top_models_accuracies.append(accuracy)\n","        top_models.append(model)  # Store the model\n","\n","# Sort top models based on f1 score in descending order\n","sorted_top_models_indices = [idx for idx, _ in sorted(enumerate(top_models_f1_scores), key=lambda x: x[1], reverse=True)]\n","top_models_indices = [top_models_indices[idx] for idx in sorted_top_models_indices[:5]]\n","\n","# Save the indices, f1 scores, and accuracies to a file for the top 5 models\n","top_models_info = pd.DataFrame({\"Model Index\": top_models_indices[:5], \"F1 Score\": top_models_f1_scores[:5], \"Accuracy\": top_models_accuracies[:5]})\n","top_models_info.to_csv(\"class-topmodels_info-seed45-torsion-t3-energy.csv\", index=False)\n","\n","# For predicting new molecules\n","# Load new molecule features\n","df_new = pd.read_csv('INPUT-NEW-MOLS-correct-HOMOLUMO.csv')\n","new_smiles_list = df_new[\"Smiles\"]\n","new_molecule_names = df_new[\"Cmpd Label\"]\n","new_mols = [Chem.MolFromSmiles(smiles) for smiles in new_smiles_list]\n","new_torsion_fingerprints = [rdMolDescriptors.GetHashedTopologicalTorsionFingerprintAsBitVect(mol) for mol in new_mols]\n","\n","# Extract HOMO and LUMO columns for new molecules\n","new_homo_values = df_new['HOMO (eV)'].astype(float)\n","new_lumo_values = df_new['LUMO (eV)'].astype(float)\n","\n","# Combine fingerprints, HOMO, and LUMO for new molecules\n","new_features = np.column_stack((np.array(new_torsion_fingerprints)[:, :2048], new_homo_values, new_lumo_values))\n","\n","\n","# Initialize predictions_df DataFrame\n","predictions_df = pd.DataFrame({\"Molecule Names\": new_molecule_names, \"Molecule SMILES\": new_smiles_list})\n","\n","# Iterate over the top 5 models\n","for idx, model in enumerate(top_models[:5]):\n","    # Assuming X_train is a DataFrame with named columns\n","    feature_names = X.columns.tolist()\n","    new_features_df = pd.DataFrame(new_features, columns=feature_names)\n","\n","    # Use the model to predict classes for new molecules\n","    predictions = model.predict(new_features_df)\n","\n","    # Save predictions to the DataFrame\n","    predictions_df[f'Model_{idx + 1}_Predictions'] = predictions\n","\n","    # Save predictions to a CSV file\n","    model_predictions_filename = f\"class-predictions-seed45-torsion-t3-energy-Model{top_models_indices[idx] + 1}.csv\"\n","    predictions_df[['Molecule Names', f'Model_{idx + 1}_Predictions']].to_csv(model_predictions_filename, index=False)\n","\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1701930073140,"user_tz":420,"elapsed":70301,"user":{"displayName":"sayantani chakraborty","userId":"16261040588437306402"}},"outputId":"eea52c40-209b-4e5d-c9bd-fcda3c6b2024","id":"lmp1EM3u6RJd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Shape of X: (63, 2050)\n"]}]}]}