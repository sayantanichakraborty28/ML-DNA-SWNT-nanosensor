{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "74fIMoAsPWR2",
        "outputId": "251e1c48-d305-4f1b-e9f7-94c3fc16d1f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rdkit-pypi\n",
            "  Downloading rdkit_pypi-2022.9.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (29.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m29.4/29.4 MB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rdkit-pypi) (1.25.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from rdkit-pypi) (9.4.0)\n",
            "Installing collected packages: rdkit-pypi\n",
            "Successfully installed rdkit-pypi-2022.9.5\n"
          ]
        }
      ],
      "source": [
        "!pip install rdkit-pypi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from rdkit import Chem\n",
        "from rdkit.Chem import AllChem\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "from sklearn.svm import LinearSVR\n",
        "from sklearn.svm import SVR\n",
        "import numpy as np\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import r2_score"
      ],
      "metadata": {
        "id": "nj_snqLLPzK4"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# upload manually with button \"Choose Files\"\n",
        "\n",
        "df = pd.read_excel('HOMO-LUMO-energies.xlsx')\n",
        "smiles_list = df[\"Smiles\"]\n"
      ],
      "metadata": {
        "id": "0nvcwxaPQmRb"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Morgan"
      ],
      "metadata": {
        "id": "w3VFbX2Brvpt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mols = [Chem.MolFromSmiles(smiles) for smiles in smiles_list]\n",
        "fingerprints = [AllChem.GetMorganFingerprintAsBitVect(mol, 2) for mol in mols]\n",
        "len(mols)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ofgX0dTrlK0",
        "outputId": "2a0b448b-7310-4920-e208-d6cacde2c77c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "63"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "homo_values = df[\"HOMO energy (eV)\"]\n",
        "lumo_values = df[\"LUMO energy (eV)\"]\n",
        "dff_values = df[\"dFF\"]\n",
        "\n",
        "# Convert the RDKit fingerprint objects to NumPy arrays\n",
        "features = np.column_stack((fingerprints, homo_values, lumo_values))"
      ],
      "metadata": {
        "id": "poCn1q2wr68s"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('out-SVR-Morgan-rbf.txt', 'w') as f:\n",
        "  for i in np.arange(0,200):\n",
        "    #splitting dataset into train and test data\n",
        "    x_train, x_test, y_train, y_test = train_test_split(features, dff_values, test_size=0.20, random_state = i)\n",
        "    regressor = SVR(kernel='rbf')\n",
        "    regressor.fit(x_train, y_train)\n",
        "  # Evaluate the model on the testing dataset\n",
        "    y_pred = regressor.predict(x_test)\n",
        "    mean_squared_error(y_test, y_pred)\n",
        "    r2_score_value = r2_score(y_test, y_pred)\n",
        "\n",
        "    print(r2_score_value, file=f)"
      ],
      "metadata": {
        "id": "7T-0CVJ8txIs"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('out-SVR-Morgan-linear.txt', 'w') as f:\n",
        "  for i in np.arange(0,200):\n",
        "    #splitting dataset into train and test data\n",
        "    x_train, x_test, y_train, y_test = train_test_split(features, dff_values, test_size=0.20, random_state = i)\n",
        "    regressor = SVR(kernel='linear')\n",
        "    regressor.fit(x_train, y_train)\n",
        "  # Evaluate the model on the testing dataset\n",
        "    y_pred = regressor.predict(x_test)\n",
        "    mean_squared_error(y_test, y_pred)\n",
        "    r2_score_value = r2_score(y_test, y_pred)\n",
        "\n",
        "    print(r2_score_value, file=f)"
      ],
      "metadata": {
        "id": "LXAIh-OruAPl"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('out-SVR-Morgan-sigmoid.txt', 'w') as f:\n",
        "  for i in np.arange(0,200):\n",
        "    #splitting dataset into train and test data\n",
        "    x_train, x_test, y_train, y_test = train_test_split(features, dff_values, test_size=0.20, random_state = i)\n",
        "    regressor = SVR(kernel='sigmoid')\n",
        "    regressor.fit(x_train, y_train)\n",
        "  # Evaluate the model on the testing dataset\n",
        "    y_pred = regressor.predict(x_test)\n",
        "    mean_squared_error(y_test, y_pred)\n",
        "    r2_score_value = r2_score(y_test, y_pred)\n",
        "\n",
        "    print(r2_score_value, file=f)"
      ],
      "metadata": {
        "id": "YBqoUVsQuQ3Q"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MACCS"
      ],
      "metadata": {
        "id": "YBvYq1Kiud6a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#MACCS\n",
        "from rdkit.Chem import MACCSkeys\n",
        "\n",
        "mols = [Chem.MolFromSmiles(smiles) for smiles in smiles_list]\n",
        "Maccs_fingerprints = [MACCSkeys.GenMACCSKeys(mol) for mol in mols]"
      ],
      "metadata": {
        "id": "yKX_HBybxa3z"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features = np.column_stack((Maccs_fingerprints, homo_values, lumo_values))\n",
        "\n",
        "with open('out-SVR-rbf-MACCS.txt', 'w') as f:\n",
        "  for i in np.arange(0,200):\n",
        "    #splitting dataset into train and test data\n",
        "    x_train, x_test, y_train, y_test = train_test_split(features, dff_values, test_size=0.20, random_state = i)\n",
        "    regressor = SVR(kernel='rbf')\n",
        "    regressor.fit(x_train, y_train)\n",
        "  # Evaluate the model on the testing dataset\n",
        "    y_pred = regressor.predict(x_test)\n",
        "    mean_squared_error(y_test, y_pred)\n",
        "    r2_score_value = r2_score(y_test, y_pred)\n",
        "\n",
        "    print(r2_score_value, file=f)\n"
      ],
      "metadata": {
        "id": "4niLExDgSYDD"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features = np.column_stack((Maccs_fingerprints, homo_values, lumo_values))\n",
        "\n",
        "with open('out-SVR-sigmoid-MACCS.txt', 'w') as f:\n",
        "  for i in np.arange(0,200):\n",
        "    #splitting dataset into train and test data\n",
        "    x_train, x_test, y_train, y_test = train_test_split(features, dff_values, test_size=0.20, random_state = i)\n",
        "    regressor = SVR(kernel='sigmoid')\n",
        "    regressor.fit(x_train, y_train)\n",
        "  # Evaluate the model on the testing dataset\n",
        "    y_pred = regressor.predict(x_test)\n",
        "    mean_squared_error(y_test, y_pred)\n",
        "    r2_score_value = r2_score(y_test, y_pred)\n",
        "\n",
        "    print(r2_score_value, file=f)"
      ],
      "metadata": {
        "id": "k_ZjYBr2mRrH"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features = np.column_stack((Maccs_fingerprints, homo_values, lumo_values))\n",
        "\n",
        "with open('out-SVR-linear-MACCS.txt', 'w') as f:\n",
        "  for i in np.arange(0,200):\n",
        "    #splitting dataset into train and test data\n",
        "    x_train, x_test, y_train, y_test = train_test_split(features, dff_values, test_size=0.20, random_state = i)\n",
        "    regressor = SVR(kernel='linear')\n",
        "    regressor.fit(x_train, y_train)\n",
        "  # Evaluate the model on the testing dataset\n",
        "    y_pred = regressor.predict(x_test)\n",
        "    mean_squared_error(y_test, y_pred)\n",
        "    r2_score_value = r2_score(y_test, y_pred)\n",
        "\n",
        "    print(r2_score_value, file=f)"
      ],
      "metadata": {
        "id": "gWSy7RXUmaiI"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Avalon"
      ],
      "metadata": {
        "id": "fcI0TdjgS7M4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install rdkit-pypi avalon_framework"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N1L1xPEaSzT5",
        "outputId": "6018780a-206b-40e3-a0a4-3115c39b21cb"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: rdkit-pypi in /usr/local/lib/python3.10/dist-packages (2022.9.5)\n",
            "Collecting avalon_framework\n",
            "  Downloading avalon_framework-1.8.2.tar.gz (3.1 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rdkit-pypi) (1.25.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from rdkit-pypi) (9.4.0)\n",
            "Building wheels for collected packages: avalon_framework\n",
            "  Building wheel for avalon_framework (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for avalon_framework: filename=avalon_framework-1.8.2-py3-none-any.whl size=3863 sha256=17a9981637f012e50844decf1e60eb01d095a1c0974c489c60079d0bb8dacfb7\n",
            "  Stored in directory: /root/.cache/pip/wheels/78/3f/5c/a65bfa8ce94f62739865cf30e5687272ee719961b4311d05e3\n",
            "Successfully built avalon_framework\n",
            "Installing collected packages: avalon_framework\n",
            "Successfully installed avalon_framework-1.8.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from rdkit import Chem\n",
        "from rdkit.Avalon import pyAvalonTools"
      ],
      "metadata": {
        "id": "mGTF9Rymgr9q"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Avalon_fingerprints = [pyAvalonTools.GetAvalonFP(mol) for mol in mols]"
      ],
      "metadata": {
        "id": "BGp_QrJqgxuQ"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features = np.column_stack((Avalon_fingerprints, homo_values, lumo_values))\n",
        "\n",
        "with open('out-SVR-rbf-Avalon.txt', 'w') as f:\n",
        "  for i in np.arange(0,200):\n",
        "    #splitting dataset into train and test data\n",
        "    x_train, x_test, y_train, y_test = train_test_split(features, dff_values, test_size=0.20, random_state = i)\n",
        "    regressor = SVR(kernel='rbf')\n",
        "    regressor.fit(x_train, y_train)\n",
        "  # Evaluate the model on the testing dataset\n",
        "    y_pred = regressor.predict(x_test)\n",
        "    mean_squared_error(y_test, y_pred)\n",
        "    r2_score_value = r2_score(y_test, y_pred)\n",
        "\n",
        "    print(r2_score_value, file=f)"
      ],
      "metadata": {
        "id": "lJzbbMDsg8Nz"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features = np.column_stack((Avalon_fingerprints, homo_values, lumo_values))\n",
        "\n",
        "with open('out-SVR-sigmoid-Avalon.txt', 'w') as f:\n",
        "  for i in np.arange(0,200):\n",
        "    #splitting dataset into train and test data\n",
        "    x_train, x_test, y_train, y_test = train_test_split(features, dff_values, test_size=0.20, random_state = i)\n",
        "    regressor = SVR(kernel='sigmoid')\n",
        "    regressor.fit(x_train, y_train)\n",
        "  # Evaluate the model on the testing dataset\n",
        "    y_pred = regressor.predict(x_test)\n",
        "    mean_squared_error(y_test, y_pred)\n",
        "    r2_score_value = r2_score(y_test, y_pred)\n",
        "\n",
        "    print(r2_score_value, file=f)"
      ],
      "metadata": {
        "id": "Xh8PiUkahSmM"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features = np.column_stack((Avalon_fingerprints, homo_values, lumo_values))\n",
        "\n",
        "with open('out-SVR-linear-Avalon.txt', 'w') as f:\n",
        "  for i in np.arange(0,200):\n",
        "    #splitting dataset into train and test data\n",
        "    x_train, x_test, y_train, y_test = train_test_split(features, dff_values, test_size=0.20, random_state = i)\n",
        "    regressor = SVR(kernel='linear')\n",
        "    regressor.fit(x_train, y_train)\n",
        "  # Evaluate the model on the testing dataset\n",
        "    y_pred = regressor.predict(x_test)\n",
        "    mean_squared_error(y_test, y_pred)\n",
        "    r2_score_value = r2_score(y_test, y_pred)\n",
        "    #r2_array = np.array(r2_score)\n",
        "    #print(r2_array, file=f)\n",
        "  #print(r2_score_value)\n",
        "\n",
        "    print(r2_score_value, file=f)"
      ],
      "metadata": {
        "id": "Xp2orN4khbfW"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Daylight"
      ],
      "metadata": {
        "id": "U-InDp1dS9S1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from rdkit import Chem\n",
        "from rdkit.Chem import DataStructs\n",
        "Daylight_fingerprints = [Chem.RDKFingerprint(mol) for mol in mols]"
      ],
      "metadata": {
        "id": "Gv9p5KIfh0ui"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features = np.column_stack((Daylight_fingerprints, homo_values, lumo_values))\n",
        "\n",
        "with open('out-SVR-rbf-Daylight.txt', 'w') as f:\n",
        "  for i in np.arange(0,200):\n",
        "    #splitting dataset into train and test data\n",
        "    x_train, x_test, y_train, y_test = train_test_split(features, dff_values, test_size=0.20, random_state = i)\n",
        "    regressor = SVR(kernel='rbf')\n",
        "    regressor.fit(x_train, y_train)\n",
        "  # Evaluate the model on the testing dataset\n",
        "    y_pred = regressor.predict(x_test)\n",
        "    mean_squared_error(y_test, y_pred)\n",
        "    r2_score_value = r2_score(y_test, y_pred)\n",
        "\n",
        "    print(r2_score_value, file=f)"
      ],
      "metadata": {
        "id": "xbKrI1rXhz5s"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features = np.column_stack((Daylight_fingerprints, homo_values, lumo_values))\n",
        "\n",
        "with open('out-SVR-linear-Daylight.txt', 'w') as f:\n",
        "  for i in np.arange(0,200):\n",
        "    #splitting dataset into train and test data\n",
        "    x_train, x_test, y_train, y_test = train_test_split(features, dff_values, test_size=0.20, random_state = i)\n",
        "    regressor = SVR(kernel='linear')\n",
        "    regressor.fit(x_train, y_train)\n",
        "  # Evaluate the model on the testing dataset\n",
        "    y_pred = regressor.predict(x_test)\n",
        "    mean_squared_error(y_test, y_pred)\n",
        "    r2_score_value = r2_score(y_test, y_pred)\n",
        "\n",
        "    print(r2_score_value, file=f)"
      ],
      "metadata": {
        "id": "rP7ZucNdi4-d"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features = np.column_stack((Daylight_fingerprints, homo_values, lumo_values))\n",
        "\n",
        "with open('out-SVR-sigmoid-Daylight.txt', 'w') as f:\n",
        "  for i in np.arange(0,200):\n",
        "    #splitting dataset into train and test data\n",
        "    x_train, x_test, y_train, y_test = train_test_split(features, dff_values, test_size=0.20, random_state = i)\n",
        "    regressor = SVR(kernel='sigmoid')\n",
        "    regressor.fit(x_train, y_train)\n",
        "  # Evaluate the model on the testing dataset\n",
        "    y_pred = regressor.predict(x_test)\n",
        "    mean_squared_error(y_test, y_pred)\n",
        "    r2_score_value = r2_score(y_test, y_pred)\n",
        "\n",
        "    print(r2_score_value, file=f)"
      ],
      "metadata": {
        "id": "g5yrL9nbi-4E"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# AtomPairs"
      ],
      "metadata": {
        "id": "LMFf_W5ETAW1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from rdkit.Chem import rdMolDescriptors\n",
        "\n",
        "mols = [Chem.MolFromSmiles(smiles) for smiles in smiles_list]\n",
        "atom_pairs_fingerprints = [rdMolDescriptors.GetHashedAtomPairFingerprintAsBitVect(mol) for mol in mols]"
      ],
      "metadata": {
        "id": "WEuKhTWNjNi0"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features = np.column_stack((atom_pairs_fingerprints, homo_values, lumo_values))\n",
        "\n",
        "with open('out-SVR-sigmoid-atompairs.txt', 'w') as f:\n",
        "  for i in np.arange(0,200):\n",
        "    #splitting dataset into train and test data\n",
        "    x_train, x_test, y_train, y_test = train_test_split(features, dff_values, test_size=0.20, random_state = i)\n",
        "    regressor = SVR(kernel='sigmoid')\n",
        "    regressor.fit(x_train, y_train)\n",
        "  # Evaluate the model on the testing dataset\n",
        "    y_pred = regressor.predict(x_test)\n",
        "    mean_squared_error(y_test, y_pred)\n",
        "    r2_score_value = r2_score(y_test, y_pred)\n",
        "\n",
        "    print(r2_score_value, file=f)"
      ],
      "metadata": {
        "id": "fnsUUXmfizlZ"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features = np.column_stack((atom_pairs_fingerprints, homo_values, lumo_values))\n",
        "\n",
        "with open('out-SVR-rbf-atompairs.txt', 'w') as f:\n",
        "  for i in np.arange(0,200):\n",
        "    #splitting dataset into train and test data\n",
        "    x_train, x_test, y_train, y_test = train_test_split(features, dff_values, test_size=0.20, random_state = i)\n",
        "    regressor = SVR(kernel='rbf')\n",
        "    regressor.fit(x_train, y_train)\n",
        "  # Evaluate the model on the testing dataset\n",
        "    y_pred = regressor.predict(x_test)\n",
        "    mean_squared_error(y_test, y_pred)\n",
        "    r2_score_value = r2_score(y_test, y_pred)\n",
        "\n",
        "    print(r2_score_value, file=f)"
      ],
      "metadata": {
        "id": "aiJ9KgcqmjTu"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features = np.column_stack((atom_pairs_fingerprints, homo_values, lumo_values))\n",
        "\n",
        "with open('out-SVR-linear-atompairs.txt', 'w') as f:\n",
        "  for i in np.arange(0,200):\n",
        "    #splitting dataset into train and test data\n",
        "    x_train, x_test, y_train, y_test = train_test_split(features, dff_values, test_size=0.20, random_state = i)\n",
        "    regressor = SVR(kernel='linear')\n",
        "    regressor.fit(x_train, y_train)\n",
        "  # Evaluate the model on the testing dataset\n",
        "    y_pred = regressor.predict(x_test)\n",
        "    mean_squared_error(y_test, y_pred)\n",
        "    r2_score_value = r2_score(y_test, y_pred)\n",
        "\n",
        "    print(r2_score_value, file=f)"
      ],
      "metadata": {
        "id": "EPyTn7bITvfT"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Topological Torsion"
      ],
      "metadata": {
        "id": "fgBvGOKZT0ov"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mols = [Chem.MolFromSmiles(smiles) for smiles in smiles_list]\n",
        "torsion_fingerprints = [rdMolDescriptors.GetHashedTopologicalTorsionFingerprintAsBitVect(mol) for mol in mols]"
      ],
      "metadata": {
        "id": "kdly3qxLT6Zn"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features = np.column_stack((torsion_fingerprints, homo_values, lumo_values))\n",
        "\n",
        "with open('out-SVR-linear-torsion.txt', 'w') as f:\n",
        "  for i in np.arange(0,200):\n",
        "    #splitting dataset into train and test data\n",
        "    x_train, x_test, y_train, y_test = train_test_split(features, dff_values, test_size=0.20, random_state = i)\n",
        "    regressor = SVR(kernel='linear')\n",
        "    regressor.fit(x_train, y_train)\n",
        "  # Evaluate the model on the testing dataset\n",
        "    y_pred = regressor.predict(x_test)\n",
        "    mean_squared_error(y_test, y_pred)\n",
        "    r2_score_value = r2_score(y_test, y_pred)\n",
        "\n",
        "    print(r2_score_value, file=f)"
      ],
      "metadata": {
        "id": "B1uCnIMAUEtB"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features = np.column_stack((torsion_fingerprints, homo_values, lumo_values))\n",
        "\n",
        "with open('out-SVR-rbf-torsion.txt', 'w') as f:\n",
        "  for i in np.arange(0,200):\n",
        "    #splitting dataset into train and test data\n",
        "    x_train, x_test, y_train, y_test = train_test_split(features, dff_values, test_size=0.20, random_state = i)\n",
        "    regressor = SVR(kernel='rbf')\n",
        "    regressor.fit(x_train, y_train)\n",
        "  # Evaluate the model on the testing dataset\n",
        "    y_pred = regressor.predict(x_test)\n",
        "    mean_squared_error(y_test, y_pred)\n",
        "    r2_score_value = r2_score(y_test, y_pred)\n",
        "\n",
        "    print(r2_score_value, file=f)"
      ],
      "metadata": {
        "id": "DTuorzcqULW4"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features = np.column_stack((torsion_fingerprints, homo_values, lumo_values))\n",
        "\n",
        "with open('out-SVR-sigmoid-torsion.txt', 'w') as f:\n",
        "  for i in np.arange(0,200):\n",
        "    #splitting dataset into train and test data\n",
        "    x_train, x_test, y_train, y_test = train_test_split(features, dff_values, test_size=0.20, random_state = i)\n",
        "    regressor = SVR(kernel='sigmoid')\n",
        "    regressor.fit(x_train, y_train)\n",
        "  # Evaluate the model on the testing dataset\n",
        "    y_pred = regressor.predict(x_test)\n",
        "    mean_squared_error(y_test, y_pred)\n",
        "    r2_score_value = r2_score(y_test, y_pred)\n",
        "\n",
        "    print(r2_score_value, file=f)"
      ],
      "metadata": {
        "id": "Oh_n0357URUY"
      },
      "execution_count": 43,
      "outputs": []
    }
  ]
}